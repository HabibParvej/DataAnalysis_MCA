{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHBi5g4izH2MGfJ15PZxAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HabibParvej/DataAnalysis_MCA/blob/main/Day3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 715,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTL-PLyPldHv",
        "outputId": "9795ed4d-ad2d-4ced-94d6-1840bb2ac00c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas is successfully imported, Version 2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Importing the pandas library using the satndard alias \"pd\"\n",
        "import pandas as pd\n",
        "\n",
        "# Let's verify it works by checking the version\n",
        "print(\"Pandas is successfully imported, Version\",pd.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating empty series\n",
        "s = pd.Series()\n",
        "# Display the series\n",
        "print(\"Resultant Empty Series\",s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX6qlua1l432",
        "outputId": "ef2cea02-9368-41e9-9d51-625cf430406b"
      },
      "execution_count": 716,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultant Empty Series Series([], dtype: object)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Series from a Python list\n",
        "\n",
        "# Step 1: Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Step 2: Create a basic Python list of monthly active users (MAUs) for an app\n",
        "mau_list = [1500, 1800, 2100, 2500, 3000]\n",
        "\n",
        "# Step 3: Create a Pandas Series from the list\n",
        "monthly_users = pd.Series(mau_list)\n",
        "\n",
        "# Step 4: Display the Series\n",
        "print(\"Monthly Active Users (MAU):\")\n",
        "print(monthly_users)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXpn3rtnmawV",
        "outputId": "97b2d2a0-49a8-4610-d121-ecf16ca15969"
      },
      "execution_count": 717,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monthly Active Users (MAU):\n",
            "0    1500\n",
            "1    1800\n",
            "2    2100\n",
            "3    2500\n",
            "4    3000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating series from NumPy ndarray with customize index\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a NumPy array with daily sales numbers\n",
        "daily_sales_array = np.array([250, 300, 400, 500, 450])\n",
        "\n",
        "# Step 2: Create a Series from the NumPy array\n",
        "daily_sales = pd.Series(daily_sales_array, index=['Mon', 'Tue', 'Wed', 'Thu', 'Fri'])\n",
        "\n",
        "# Step 3: Print the Series\n",
        "print(\"Daily Sales Data:\")\n",
        "print(daily_sales)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhUHStF2msAm",
        "outputId": "8bc3e0ab-400c-4c23-8cd7-d40722133940"
      },
      "execution_count": 718,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily Sales Data:\n",
            "Mon    250\n",
            "Tue    300\n",
            "Wed    400\n",
            "Thu    500\n",
            "Fri    450\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary with country names as keys and population as values\n",
        "pop_dict = {\n",
        "    'India': 112,\n",
        "    'USA': 334,\n",
        "    'China': 232,\n",
        "    'Brazil': 345,\n",
        "    'UK': 121\n",
        "}\n",
        "\n",
        "# Create Series from dictionary\n",
        "population_series = pd.Series(pop_dict)\n",
        "\n",
        "# Print the series\n",
        "print(\"Population By Country\")\n",
        "print(population_series)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Pe9U8Zn7rN",
        "outputId": "e4619b32-ce1b-4d0e-eab9-655a2c365325"
      },
      "execution_count": 719,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Population By Country\n",
            "India     112\n",
            "USA       334\n",
            "China     232\n",
            "Brazil    345\n",
            "UK        121\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series from scalar value\n",
        "\n",
        "# Representing a single product price applied across 4 branches\n",
        "import pandas as pd\n",
        "price_scalar = pd.Series(999, index=['Miami', 'Los Angeles', 'Mumbai', 'Tokyo'])\n",
        "\n",
        "print(\"Price of Product X across branches:\")\n",
        "print(price_scalar)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPX0yN51pmrb",
        "outputId": "a8095739-b346-4b21-e053-fffa02def671"
      },
      "execution_count": 720,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price of Product X across branches:\n",
            "Miami          999\n",
            "Los Angeles    999\n",
            "Mumbai         999\n",
            "Tokyo          999\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing series elements by position\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a Series with monthly revenue data\n",
        "monthly_revenue = pd.Series(\n",
        "    [20, 25, 30, 28, 35],\n",
        "    index=['Jan', 'Feb', 'Mar', 'Apr', 'May']\n",
        ")\n",
        "\n",
        "# Step 2: Access the first and last month's revenue using position-based indexing\n",
        "print(\"January Revenue:\", monthly_revenue.iloc[0])   # Position 0\n",
        "print(\"May Revenue:\", monthly_revenue.iloc[-1])      # Last position"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl4xRX3cqj_3",
        "outputId": "579156d6-9f35-4890-dee5-c35a1cef0f3d"
      },
      "execution_count": 721,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "January Revenue: 20\n",
            "May Revenue: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing by label\n",
        "\n",
        "# Step 1: Create a Series with monthly revenue data\n",
        "monthly_revenue = pd.Series(\n",
        "    [20, 25, 30, 28, 35],\n",
        "    index=['Jan', 'Feb', 'Mar', 'Apr', 'May']\n",
        ")\n",
        "\n",
        "# Access revenue for March directly using label\n",
        "print(\"March Revenue:\", monthly_revenue['Mar'])\n",
        "\n",
        "# Slicing using index positions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H6tBCF2rlvq",
        "outputId": "a8e301de-ff7a-4b25-e854-27328d6edaea"
      },
      "execution_count": 722,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "March Revenue: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a Series showing number of passengers\n",
        "# (in thousands) per day in a week\n",
        "passenger_load = pd.Series(\n",
        "    [105, 134, 120, 145, 160, 178, 150],\n",
        "    index=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        ")\n",
        "\n",
        "# Step 2: Apply various slicing techniques\n",
        "\n",
        "# Select alternate days starting from Tuesday to Saturday\n",
        "print(\"Slicing [1:6:2] (Tue to Sat, alternate days):\\n\", passenger_load[1:6:2])\n",
        "# Select midweek traffic from Wednesday to Friday\n",
        "print(\"\\nSlicing [2:5] (Wed to Fri):\\n\", passenger_load[2:5])\n",
        "# Select all data from Thursday onwards\n",
        "print(\"\\nSlicing [3:] (Thu to Sun):\\n\", passenger_load[3:])\n",
        "# Select early week (Mon to Thu)\n",
        "print(\"\\nSlicing [:4] (Mon to Thu):\\n\", passenger_load[:4])\n",
        "# Select the entire week\n",
        "print(\"\\nSlicing [:] (All days):\\n\", passenger_load[:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ6YG3WStQO2",
        "outputId": "83236555-3636-4011-990a-49098157b89f"
      },
      "execution_count": 723,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slicing [1:6:2] (Tue to Sat, alternate days):\n",
            " Tue    134\n",
            "Thu    145\n",
            "Sat    178\n",
            "dtype: int64\n",
            "\n",
            "Slicing [2:5] (Wed to Fri):\n",
            " Wed    120\n",
            "Thu    145\n",
            "Fri    160\n",
            "dtype: int64\n",
            "\n",
            "Slicing [3:] (Thu to Sun):\n",
            " Thu    145\n",
            "Fri    160\n",
            "Sat    178\n",
            "Sun    150\n",
            "dtype: int64\n",
            "\n",
            "Slicing [:4] (Mon to Thu):\n",
            " Mon    105\n",
            "Tue    134\n",
            "Wed    120\n",
            "Thu    145\n",
            "dtype: int64\n",
            "\n",
            "Slicing [:] (All days):\n",
            " Mon    105\n",
            "Tue    134\n",
            "Wed    120\n",
            "Thu    145\n",
            "Fri    160\n",
            "Sat    178\n",
            "Sun    150\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a Pandas Series using index labels\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a Series of daily ticket sales (in thousands) over a week\n",
        "ticket_sales = pd.Series(\n",
        "    [120, 135, 128, 160, 142, 170, 155],\n",
        "    index=[\n",
        "        '2024-06-01',\n",
        "        '2024-06-02',\n",
        "        '2024-06-03',\n",
        "        '2024-06-04',\n",
        "        '2024-06-05',\n",
        "        '2024-06-06',\n",
        "        '2024-06-07'\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Slice sales from June 2nd to June 5th using index labels\n",
        "selected_sales = ticket_sales['2024-06-02':'2024-06-05']\n",
        "\n",
        "# Display the result\n",
        "print(\"Ticket sales from June 2 to June 5:\\n\", selected_sales)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rwpAlsAtrXN",
        "outputId": "078a2f7e-7247-4ded-b243-410349dde65e"
      },
      "execution_count": 724,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ticket sales from June 2 to June 5:\n",
            " 2024-06-02    135\n",
            "2024-06-03    128\n",
            "2024-06-04    160\n",
            "2024-06-05    142\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional access with boolean indexing\n",
        "\n",
        "# Use Boolean indexing to filter days with significant delays (>30 minutes)\n",
        "high_delay_days = passenger_load[passenger_load > 130]\n",
        "\n",
        "# Display the result\n",
        "print(\"Days with flight delays greater than 30 minutes:\\n\", high_delay_days)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aoj70sgUw4QV",
        "outputId": "041598cb-3a95-4151-d0b3-361bda849059"
      },
      "execution_count": 725,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Days with flight delays greater than 30 minutes:\n",
            " Tue    134\n",
            "Thu    145\n",
            "Fri    160\n",
            "Sat    178\n",
            "Sun    150\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access using .get() to avoid errors\n",
        "# Try accessing a Days that may not exist\n",
        "print(passenger_load.get('Tue', 'Data not available'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1rw4JxOypJw",
        "outputId": "9ea2a72f-51b7-4ab8-d251-9bc9c3ceeae8"
      },
      "execution_count": 726,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Convert dict to Series\n",
        "pop_series = pd.Series(pop_dict)\n",
        "\n",
        "# Step 2: Now check attributes\n",
        "print(\"Data type of population values:\", pop_series.dtype)\n",
        "print(\"Total records (countries):\", pop_series.shape)\n",
        "print(\"Index labels:\", pop_series.index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwEzBwJRzSTK",
        "outputId": "9f729f57-4629-4558-fd8a-cbee566e5f6a"
      },
      "execution_count": 727,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data type of population values: int64\n",
            "Total records (countries): (5,)\n",
            "Index labels: Index(['India', 'USA', 'China', 'Brazil', 'UK'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly cloud costs (USD)\n",
        "cloud_cost = pd.Series(\n",
        "    [10000, 12500, 11000, 14500, 15000, 12500],\n",
        "    index=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\n",
        ")\n",
        "\n",
        "# Find months where cost exceeded $13,000\n",
        "high_cost = cloud_cost > 13000\n",
        "\n",
        "# Find months where cost is either below $12,000 or above $14,500\n",
        "outlier_months = (cloud_cost < 12000) | (cloud_cost > 14500)\n",
        "\n",
        "# Negate condition: find months not exceeding $13,000\n",
        "within_budget = ~high_cost\n",
        "\n",
        "# Use Boolean mask to extract high cost values\n",
        "filtered_costs = cloud_cost[high_cost]\n",
        "\n",
        "# Use .where() to keep only values above $13,000, others become NaN\n",
        "where_example = cloud_cost.where(cloud_cost > 13000)\n",
        "\n",
        "# Use .mask() to hide costs below $13,000; keep rest\n",
        "mask_example = cloud_cost.mask(cloud_cost < 13000)\n",
        "\n",
        "# Use .clip() to restrict all values between $12,000 and $14,000\n",
        "clipped_cost = cloud_cost.clip(lower=12000, upper=14000)\n",
        "\n",
        "print(\"Months with Cost > $13,000:\\n\",high_cost)\n",
        "print(\"\\nOutlier Months (< $12k or > $14.5k):\\n\", outlier_months)\n",
        "print(\"\\nMonths Within Budget (<= $13,000):\\n\", within_budget)\n",
        "print(\"\\nFiltered High Costs:\\n\", filtered_costs)\n",
        "print(\"\\nUsing where():\\n\", where_example)\n",
        "print(\"\\nUsing mask():\\n\", mask_example)\n",
        "print(\"\\nClipped Values between $12k and $14k:\\n\", clipped_cost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUv6o-px0UT4",
        "outputId": "fc6b040f-7536-481a-b1d6-2a06d765a1b8"
      },
      "execution_count": 728,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Months with Cost > $13,000:\n",
            " Jan    False\n",
            "Feb    False\n",
            "Mar    False\n",
            "Apr     True\n",
            "May     True\n",
            "Jun    False\n",
            "dtype: bool\n",
            "\n",
            "Outlier Months (< $12k or > $14.5k):\n",
            " Jan     True\n",
            "Feb    False\n",
            "Mar     True\n",
            "Apr    False\n",
            "May     True\n",
            "Jun    False\n",
            "dtype: bool\n",
            "\n",
            "Months Within Budget (<= $13,000):\n",
            " Jan     True\n",
            "Feb     True\n",
            "Mar     True\n",
            "Apr    False\n",
            "May    False\n",
            "Jun     True\n",
            "dtype: bool\n",
            "\n",
            "Filtered High Costs:\n",
            " Apr    14500\n",
            "May    15000\n",
            "dtype: int64\n",
            "\n",
            "Using where():\n",
            " Jan        NaN\n",
            "Feb        NaN\n",
            "Mar        NaN\n",
            "Apr    14500.0\n",
            "May    15000.0\n",
            "Jun        NaN\n",
            "dtype: float64\n",
            "\n",
            "Using mask():\n",
            " Jan        NaN\n",
            "Feb        NaN\n",
            "Mar        NaN\n",
            "Apr    14500.0\n",
            "May    15000.0\n",
            "Jun        NaN\n",
            "dtype: float64\n",
            "\n",
            "Clipped Values between $12k and $14k:\n",
            " Jan    12000\n",
            "Feb    12500\n",
            "Mar    12000\n",
            "Apr    14000\n",
            "May    14000\n",
            "Jun    12500\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .map()\n",
        "\n",
        "# Mapping department codes to names in a payroll system\n",
        "# Department codes of employees\n",
        "import pandas as pd\n",
        "\n",
        "dept_codes = pd.Series(['HR', 'ENG', 'MKT', 'HR', 'FIN', 'ENG'])\n",
        "print(\"Before Mapping\\n:\",dept_codes)\n",
        "# Mapping to full department names\n",
        "dept_names = {\n",
        "    'HR': 'Human Resources',\n",
        "    'ENG': 'Engineering',\n",
        "    'MKT': 'Marketing',\n",
        "    'FIN': 'Finance'\n",
        "}\n",
        "\n",
        "# Mapping with .map()\n",
        "mapped = dept_codes.map(dept_names)\n",
        "print(\"Mapped Department Names:\\n\",mapped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VChdbSa38j4",
        "outputId": "3504f8d1-34bf-4177-811c-7d7c64f3a0c6"
      },
      "execution_count": 729,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Mapping\n",
            ": 0     HR\n",
            "1    ENG\n",
            "2    MKT\n",
            "3     HR\n",
            "4    FIN\n",
            "5    ENG\n",
            "dtype: object\n",
            "Mapped Department Names:\n",
            " 0    Human Resources\n",
            "1        Engineering\n",
            "2          Marketing\n",
            "3    Human Resources\n",
            "4            Finance\n",
            "5        Engineering\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keys in the dictionary represent column names in the DataFrame\n",
        "# Each key maps to a list of values, where each element corresponds to\n",
        "cholesterol_data = {\n",
        "    'Patient_ID': ['P101', 'P102', 'P103', 'P104', 'P105'],\n",
        "    'Age': [45, 54, 38, 50, 60],\n",
        "    'Cholesterol_mg/dL': [190, 205, 180, 220, 199],\n",
        "    'On_Status': [True, False, True, False, True]\n",
        "}\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "df_medical = pd.DataFrame(cholesterol_data)\n",
        "print(df_medical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OimMQiUbDrO-",
        "outputId": "69866c97-6363-4b45-e448-ac397db697b8"
      },
      "execution_count": 730,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Patient_ID  Age  Cholesterol_mg/dL  On_Status\n",
            "0       P101   45                190       True\n",
            "1       P102   54                205      False\n",
            "2       P103   38                180       True\n",
            "3       P104   50                220      False\n",
            "4       P105   60                199       True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DataFrame from list\n",
        "# Seismic magnitude data for different regions\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Each inner list represents a row: [Region, Year, Magnitude]\n",
        "earthquake_data = [\n",
        "    ['California', 2016, 6.5],\n",
        "    ['Japan', 2018, 7.3],\n",
        "    ['Chile', 2020, 6.9],\n",
        "    ['Nepal', 2015, 7.8],\n",
        "    ['Indonesia', 2019, 6.1]\n",
        "]\n",
        "\n",
        "# Convert list of lists to DataFrame and specify column names\n",
        "df_geo = pd.DataFrame(earthquake_data, columns=['Region', 'Year', 'Magnitude'])\n",
        "print(df_geo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-73w4U2aFCcv",
        "outputId": "af1e2a2f-6e0d-4d03-9607-d2e8c88363a1"
      },
      "execution_count": 731,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Region  Year  Magnitude\n",
            "0  California  2016        6.5\n",
            "1       Japan  2018        7.3\n",
            "2       Chile  2020        6.9\n",
            "3       Nepal  2015        7.8\n",
            "4   Indonesia  2019        6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DataFrame from NumPy ndarray\n",
        "# Intensity readings from two telescope sensors for 5 stars\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Each row represents a star; each column a sensor reading\n",
        "astro_array = np.array([\n",
        "    [1500, 1600],\n",
        "    [1700, 1800],\n",
        "    [1650, 1720],\n",
        "    [1580, 1625],\n",
        "    [1775, 1890]\n",
        "])\n",
        "\n",
        "# Create DataFrame from the NumPy array with appropriate column names\n",
        "df_astro = pd.DataFrame(astro_array, columns=['Sensor_A_Intensity', 'Sensor_B_Intensity'])\n",
        "print(df_astro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS8rHH96GTaa",
        "outputId": "00769da0-1e6e-41a9-b876-65a77ee8aabb"
      },
      "execution_count": 732,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Sensor_A_Intensity  Sensor_B_Intensity\n",
            "0                1500                1600\n",
            "1                1700                1800\n",
            "2                1650                1720\n",
            "3                1580                1625\n",
            "4                1775                1890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and read DataFrame\n",
        "# Create the DataFrame with air quality data\n",
        "air_quality_data = {\n",
        "    'City': ['Delhi', 'Beijing', 'Los Angeles', 'Paris', 'Sydney'],\n",
        "    'PM2.5': [250, 180, 90, 60, 40],\n",
        "    'PM10': [300, 220, 110, 80, 55],\n",
        "    'NO2': [40, 60, 30, 25, 20],\n",
        "    'CO': [1.1, 1.3, 0.7, 0.6, 0.4]\n",
        "}\n",
        "\n",
        "df_air_quality = pd.DataFrame(air_quality_data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_air_quality.to_csv('air_quality_data.csv', index=False)\n",
        "\n",
        "# Optional: Load it back to confirm\n",
        "df_loaded = pd.read_csv('air_quality_data.csv')\n",
        "print(df_loaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVSP2xuBGglU",
        "outputId": "f5455834-0a40-425d-8b97-af48cac52c51"
      },
      "execution_count": 733,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          City  PM2.5  PM10  NO2   CO\n",
            "0        Delhi    250   300   40  1.1\n",
            "1      Beijing    180   220   60  1.3\n",
            "2  Los Angeles     90   110   30  0.7\n",
            "3        Paris     60    80   25  0.6\n",
            "4       Sydney     40    55   20  0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cholesterol_data = {\n",
        "    'Patient_ID': ['P101', 'P102', 'P103', 'P104', 'P105','P100','P108','P160','P140','P104'],\n",
        "    'Age': [45, 54, 38, 50, 60, 45, 76, 76, 67, 64],\n",
        "    'Cholesterol_mg/dL': [190, 205, 180, 220, 199, 199, 210, 210, 199, 220],\n",
        "    'On_Statins': [True, False, True, False, True, False, True, False, True, False]\n",
        "}\n",
        "df_health = pd.DataFrame(cholesterol_data)\n",
        "print(df_health)\n",
        "# # Save the DataFrame to a CSV file\n",
        "# df_health.to_csv('health.csv', index=False)\n",
        "\n",
        "# # Optional: Load it back to confirm\n",
        "# df_loaded = pd.read_csv('health.csv')\n",
        "# print(df_loaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9owP1z6wHMDr",
        "outputId": "98b3e1e7-148a-4bd7-847e-8e237e2ad9ef"
      },
      "execution_count": 734,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Patient_ID  Age  Cholesterol_mg/dL  On_Statins\n",
            "0       P101   45                190        True\n",
            "1       P102   54                205       False\n",
            "2       P103   38                180        True\n",
            "3       P104   50                220       False\n",
            "4       P105   60                199        True\n",
            "5       P100   45                199       False\n",
            "6       P108   76                210        True\n",
            "7       P160   76                210       False\n",
            "8       P140   67                199        True\n",
            "9       P104   64                220       False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 5 rows of the DataFrame\n",
        "print(\"Display first 5 rows\")\n",
        "print(df_health.head())\n",
        "\n",
        "print(\"\\nDisplay first 3 rows\")\n",
        "# Optionally, view a custom number of rows (e.g., first 3)\n",
        "print(df_health.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKRU6qDuI309",
        "outputId": "62aca3a3-1cc8-409a-eab4-f625e0644270"
      },
      "execution_count": 735,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Display first 5 rows\n",
            "  Patient_ID  Age  Cholesterol_mg/dL  On_Statins\n",
            "0       P101   45                190        True\n",
            "1       P102   54                205       False\n",
            "2       P103   38                180        True\n",
            "3       P104   50                220       False\n",
            "4       P105   60                199        True\n",
            "\n",
            "Display first 3 rows\n",
            "  Patient_ID  Age  Cholesterol_mg/dL  On_Statins\n",
            "0       P101   45                190        True\n",
            "1       P102   54                205       False\n",
            "2       P103   38                180        True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .describe() - Summary statistics for numeric data\n",
        "\n",
        "# Get descriptive stats for numeric columns only\n",
        "print(\"Description of DataFrame\\n\", df_health.describe())\n",
        "\n",
        "# Optional: Include all data types (numeric + object)\n",
        "print(\"\\nDetailed description of DataFrame\\n\", df_health.describe(include='all'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOJgHHR2K8dJ",
        "outputId": "80a7aa4f-3e0c-4d5d-b060-afb9d5dc1ff8"
      },
      "execution_count": 736,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description of DataFrame\n",
            "              Age  Cholesterol_mg/dL\n",
            "count  10.000000          10.000000\n",
            "mean   57.500000         203.200000\n",
            "std    13.268593          12.585706\n",
            "min    38.000000         180.000000\n",
            "25%    46.250000         199.000000\n",
            "50%    57.000000         202.000000\n",
            "75%    66.250000         210.000000\n",
            "max    76.000000         220.000000\n",
            "\n",
            "Detailed description of DataFrame\n",
            "        Patient_ID        Age  Cholesterol_mg/dL On_Statins\n",
            "count          10  10.000000          10.000000         10\n",
            "unique          9        NaN                NaN          2\n",
            "top          P104        NaN                NaN       True\n",
            "freq            2        NaN                NaN          5\n",
            "mean          NaN  57.500000         203.200000        NaN\n",
            "std           NaN  13.268593          12.585706        NaN\n",
            "min           NaN  38.000000         180.000000        NaN\n",
            "25%           NaN  46.250000         199.000000        NaN\n",
            "50%           NaN  57.000000         202.000000        NaN\n",
            "75%           NaN  66.250000         210.000000        NaN\n",
            "max           NaN  76.000000         220.000000        NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .loc[] - Access rows and columns using labels (names)\n",
        "\n",
        "# Get details of Patient ID and Age\n",
        "# loc[row_label, column_name]\n",
        "sf = df_health.loc[1, ['Age', 'Patient_ID']]\n",
        "print(\"Located Data is\\n\", sf)\n",
        "\n",
        "# Get all fragile shipments\n",
        "data = df_health.loc[df_health['On_Statins'] == True]\n",
        "print(\"\\nData:\\n\", data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b72dZgkL8qf",
        "outputId": "5f60ae12-ed57-4153-8977-506895cfe155"
      },
      "execution_count": 737,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Located Data is\n",
            " Age             54\n",
            "Patient_ID    P102\n",
            "Name: 1, dtype: object\n",
            "\n",
            "Data:\n",
            "   Patient_ID  Age  Cholesterol_mg/dL  On_Statins\n",
            "0       P101   45                190        True\n",
            "2       P103   38                180        True\n",
            "4       P105   60                199        True\n",
            "6       P108   76                210        True\n",
            "8       P140   67                199        True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iloc[] - Access rows/columns using positional indices\n",
        "\n",
        "# Get the first 2  records\n",
        "# iloc[row_index_position, column_index_position]\n",
        "first_two = df_health.iloc[0:2]\n",
        "print(\"First 2  records\\n\", first_two)\n",
        "\n",
        "# Get the Status\n",
        "weights_status = df_health.iloc[2:4, 3:5]\n",
        "print(\"\\nStatus\\n\", weights_status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNeb5w-LMrM4",
        "outputId": "c13f0174-4e91-456e-f6ec-f005245c1064"
      },
      "execution_count": 738,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 2  records\n",
            "   Patient_ID  Age  Cholesterol_mg/dL  On_Statins\n",
            "0       P101   45                190        True\n",
            "1       P102   54                205       False\n",
            "\n",
            "Status\n",
            "    On_Statins\n",
            "2        True\n",
            "3       False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .at[] - Access a single cell using row label and column name\n",
        "\n",
        "# .at[row_label, column_label]\n",
        "# Returns a scalar value\n",
        "# Retrieve the status\n",
        "status = df_health.at[1, 'Age']\n",
        "print(status)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbejCrKfQBVe",
        "outputId": "f07b0576-c574-4075-ecca-2058debfd071"
      },
      "execution_count": 739,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .iat[] - Access a single cell using row and column index\n",
        "\n",
        "# Get the 'Weight_kg' value of the 3rd record (index 2, column index 3)\n",
        "# .iat[row_index, column_index]\n",
        "weight_value = df_health.iat[2, 3]\n",
        "print(\"value of the 3rd record =\", weight_value)\n",
        "\n",
        "# query() - Filter rows using a string-based expression, like SQL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KTTuMS9R6Um",
        "outputId": "37b509ee-1be6-41da-8b43-d043d1ddd05f"
      },
      "execution_count": 740,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of the 3rd record = True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Convert Age Years to Months\n",
        "df_health['Age_in_Months'] = df_health['Age'] * 12 # Create a new Column in the existing Data\n",
        "print(\"age from years to months\\n\", df_health['Age_in_Months'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxquTlO_Skge",
        "outputId": "9db5b91f-d2cb-40c8-9b92-4dd4b477dd9e"
      },
      "execution_count": 741,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age from years to months\n",
            " 0    540\n",
            "1    648\n",
            "2    456\n",
            "3    600\n",
            "4    720\n",
            "5    540\n",
            "6    912\n",
            "7    912\n",
            "8    804\n",
            "9    768\n",
            "Name: Age_in_Months, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_health)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgIzLXRQTapX",
        "outputId": "aa71dc6e-a039-40b7-fde3-bbccce6c4a75"
      },
      "execution_count": 742,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Patient_ID  Age  Cholesterol_mg/dL  On_Statins  Age_in_Months\n",
            "0       P101   45                190        True            540\n",
            "1       P102   54                205       False            648\n",
            "2       P103   38                180        True            456\n",
            "3       P104   50                220       False            600\n",
            "4       P105   60                199        True            720\n",
            "5       P100   45                199       False            540\n",
            "6       P108   76                210        True            912\n",
            "7       P160   76                210       False            912\n",
            "8       P140   67                199        True            804\n",
            "9       P104   64                220       False            768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before update\n",
        "print(\"\\nStatus - Before:\\n\", df_health['On_Statins'])\n",
        "\n",
        "# Update values: if it's a boolean column\n",
        "df_health.loc[df_health['On_Statins'] == True, 'On_Statins'] = 'On'\n",
        "\n",
        "# After update\n",
        "print(\"\\nStatus - After:\\n\", df_health['On_Statins'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLNzmlUfT6Mb",
        "outputId": "db447e18-7d04-4e0a-f0c3-3371c21794c3"
      },
      "execution_count": 743,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Status - Before:\n",
            " 0     True\n",
            "1    False\n",
            "2     True\n",
            "3    False\n",
            "4     True\n",
            "5    False\n",
            "6     True\n",
            "7    False\n",
            "8     True\n",
            "9    False\n",
            "Name: On_Statins, dtype: bool\n",
            "\n",
            "Status - After:\n",
            " 0       On\n",
            "1    False\n",
            "2       On\n",
            "3    False\n",
            "4       On\n",
            "5    False\n",
            "6       On\n",
            "7    False\n",
            "8       On\n",
            "9    False\n",
            "Name: On_Statins, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-743-3957223621.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'On' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  df_health.loc[df_health['On_Statins'] == True, 'On_Statins'] = 'On'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating logistics shipment DataFrame\n",
        "# Creating logistics shipment DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'ShipmentID': [1001, 1002, 1003, 1004, 1005],\n",
        "    'Weight_kg': [12.5, 8.0, 15.0, 7.5, 10.0],\n",
        "    'Status': ['Delivered', 'In Transit', 'Delayed', 'Delivered', 'Delayed'],\n",
        "    'Fragile': [True, False, True, False, True],\n",
        "    'Shipping_Type': ['Air', 'Ground', 'Air', 'Ground', 'Air']\n",
        "})\n",
        "\n",
        "# 1. (Fixed) Get all delayed shipments (not 'Critical', which doesn't exist)\n",
        "delayed_df = df[df['Status'] == 'Delayed']\n",
        "print(\" Delayed Shipments:\\n\", delayed_df)\n",
        "\n",
        "# 2. Get all delayed AND air-shipped packages (heavy is not clearly defined, so we're keeping it simple)\n",
        "delayed_air_df = df[(df['Status'] == 'Delayed') & (df['Shipping_Type'] == 'Air')]\n",
        "print(\"\\nDelayed & Air-Shipped Packages:\\n\", delayed_air_df)\n",
        "\n",
        "# 3. Query for ground-shipped delayed items\n",
        "ground_delayed = df.query(\"Status == 'Delayed' and Shipping_Type == 'Ground'\")\n",
        "print(\"\\n Delayed Ground Shipments:\\n\", ground_delayed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnIeeKGzVyWx",
        "outputId": "e83a5848-2a3a-4805-b736-da9875c18da2"
      },
      "execution_count": 744,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Delayed Shipments:\n",
            "    ShipmentID  Weight_kg   Status  Fragile Shipping_Type\n",
            "2        1003       15.0  Delayed     True           Air\n",
            "4        1005       10.0  Delayed     True           Air\n",
            "\n",
            "Delayed & Air-Shipped Packages:\n",
            "    ShipmentID  Weight_kg   Status  Fragile Shipping_Type\n",
            "2        1003       15.0  Delayed     True           Air\n",
            "4        1005       10.0  Delayed     True           Air\n",
            "\n",
            " Delayed Ground Shipments:\n",
            " Empty DataFrame\n",
            "Columns: [ShipmentID, Weight_kg, Status, Fragile, Shipping_Type]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe  Arithmetc (With/Without)"
      ],
      "metadata": {
        "id": "aw0K-63gXzlv"
      },
      "execution_count": 745,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File Handling\n",
        "\n",
        "# Creating logistics shipment DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'ShipmentID': [1001, 1002, 1003, 1004, 1005],\n",
        "    'Weight_kg': [12.5, 8.0, 15.0, 7.5, 10.0],\n",
        "    'Status': ['Delivered', 'In Transit', 'Delayed', 'Delivered', 'Delayed'],\n",
        "    'Fragile': [True, False, True, False, True],\n",
        "    'Shipping_Type': ['Air', 'Ground', 'Air', 'Ground', 'Air']\n",
        "})\n",
        "\n",
        "df.to_excel('ShipmentData.xlsx',index = False)"
      ],
      "metadata": {
        "id": "plVlccyXbAN0"
      },
      "execution_count": 746,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read The excel File\n",
        "df_loaded = pd.read_excel('ShipmentData.xlsx')\n",
        "print(df_loaded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z27quk4ebCM9",
        "outputId": "1280f8b0-6137-4d82-d841-4f78b8ed81d9"
      },
      "execution_count": 747,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ShipmentID  Weight_kg      Status  Fragile Shipping_Type\n",
            "0        1001       12.5   Delivered     True           Air\n",
            "1        1002        8.0  In Transit    False        Ground\n",
            "2        1003       15.0     Delayed     True           Air\n",
            "3        1004        7.5   Delivered    False        Ground\n",
            "4        1005       10.0     Delayed     True           Air\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use all the Binary Comparisonsss\n",
        "# Assuming 'df' DataFrame is already defined, for example from a previous image:\n",
        "df = pd.DataFrame({\n",
        "    'City': ['Delhi', 'Beijing', 'Los Angeles', 'Paris', 'Sydney'],\n",
        "    'PM2.5': [250, 180, 90, 60, 40],\n",
        "    'PM10': [300, 220, 110, 80, 55],\n",
        "    'NO2': [40, 60, 30, 25, 20],\n",
        "    'CO': [1.1, 1.3, 0.7, 0.6, 0.4]\n",
        "})\n",
        "\n",
        "# Define safe threshold values (as per environmental standards)\n",
        "safe_PM25 = 100\n",
        "safe_PM10 = 200\n",
        "\n",
        "# Perform binary comparisons\n",
        "pm25_safe = df['PM2.5'] < safe_PM25      # Is PM2.5 within safe limit?\n",
        "pm10_high = df['PM10'] > safe_PM10      # Is PM10 exceeding danger level?\n",
        "pm_match = df['PM2.5'] == df['PM10']     # Are both pollutants equal?\n",
        "\n",
        "# Print comparisons\n",
        "print(\"Cities with Safe PM2.5 Levels:\\n\", pm25_safe)\n",
        "print(\"\\nCities with High PM10 Levels:\\n\", pm10_high)\n",
        "print(\"\\nCities where PM2.5 equals PM10:\\n\", pm_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw3ocq4jcM4A",
        "outputId": "e6970610-efb8-4b6b-dccf-f462f4e30f7a"
      },
      "execution_count": 748,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cities with Safe PM2.5 Levels:\n",
            " 0    False\n",
            "1    False\n",
            "2     True\n",
            "3     True\n",
            "4     True\n",
            "Name: PM2.5, dtype: bool\n",
            "\n",
            "Cities with High PM10 Levels:\n",
            " 0     True\n",
            "1     True\n",
            "2    False\n",
            "3    False\n",
            "4    False\n",
            "Name: PM10, dtype: bool\n",
            "\n",
            "Cities where PM2.5 equals PM10:\n",
            " 0    False\n",
            "1    False\n",
            "2    False\n",
            "3    False\n",
            "4    False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Boolean Functions\n",
        "\n",
        "# Create a sample DataFrame with emissions data (in mg/m³)\n",
        "data = {\n",
        "    'NOx_Emissions': [10, 20, 30],  # Nitrogen oxides (harmful gases)\n",
        "    'CO2_Emissions': [40, 50, 60]   # Carbon dioxide (global warming agent)\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"Daily Emissions Data:\\n\", df)\n",
        "\n",
        "# Binary comparison - Check if emissions are less than 25\n",
        "# Returns a DataFrame with boolean values (True/False) per element\n",
        "print(\"\\nEmissions < 25 mg/m³:\\n\", df.lt(25)) # lt = less than\n",
        "\n",
        "# Check if emissions exceed 50 mg/m³\n",
        "print(\"\\nEmissions > 50 mg/m³ (Exceeds Alert Level):\\n\", df.gt(50)) # gt = greater than\n",
        "\n",
        "# Check where emissions are exactly 30 mg/m³\n",
        "print(\"\\nEmissions == 30 mg/m³ (Match Target Day):\\n\", df.eq(30)) # eq = equal to\n",
        "\n",
        "# Check if emissions are <= 30 mg/m³ (within safe range)\n",
        "print(\"\\nEmissions <= 30 mg/m³:\\n\", df.le(30)) # le = less than or equal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9C0hP2fdi4X",
        "outputId": "b906f1cd-7aa8-4328-92e3-254886bb4bc6"
      },
      "execution_count": 749,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily Emissions Data:\n",
            "    NOx_Emissions  CO2_Emissions\n",
            "0             10             40\n",
            "1             20             50\n",
            "2             30             60\n",
            "\n",
            "Emissions < 25 mg/m³:\n",
            "    NOx_Emissions  CO2_Emissions\n",
            "0           True          False\n",
            "1           True          False\n",
            "2          False          False\n",
            "\n",
            "Emissions > 50 mg/m³ (Exceeds Alert Level):\n",
            "    NOx_Emissions  CO2_Emissions\n",
            "0          False          False\n",
            "1          False          False\n",
            "2          False           True\n",
            "\n",
            "Emissions == 30 mg/m³ (Match Target Day):\n",
            "    NOx_Emissions  CO2_Emissions\n",
            "0          False          False\n",
            "1          False          False\n",
            "2           True          False\n",
            "\n",
            "Emissions <= 30 mg/m³:\n",
            "    NOx_Emissions  CO2_Emissions\n",
            "0           True          False\n",
            "1           True          False\n",
            "2           True          False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample DataFrame for example\n",
        "df = pd.DataFrame({\n",
        "    'ShipmentID': [1001, 1002, 1003, 1004, 1005],\n",
        "    'Weight(kg)': [800, 1200, 900, 950, 700],\n",
        "    'Status': ['Delivered', 'In Transit', 'Delayed', 'No', 'No'],\n",
        "    'OriginPort': ['Rotterdam', 'Shanghai', 'Hamburg', 'Rotterdam', 'Hamburg']\n",
        "})\n",
        "\n",
        "# 1. Define a set of European ports\n",
        "europe_ports = ['Rotterdam', 'Hamburg']\n",
        "\n",
        "# 2. Apply advanced filtering\n",
        "filtered_df = df[\n",
        "    (df['Status'] == 'No') &  # Only those not delivered\n",
        "    (df['Weight(kg)'] < 1000) &  # Weight less than 1000 kg\n",
        "    (df['OriginPort'].isin(europe_ports))  # From European ports\n",
        "]\n",
        "\n",
        "# 3. Display the result\n",
        "print(\"\\nFiltered Shipments (Undelivered, <1000kg, From Europe):\")\n",
        "print(filtered_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcp3fOv5eUd_",
        "outputId": "e2838c9c-60ff-4ccc-b518-9aa55e1eda64"
      },
      "execution_count": 750,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Filtered Shipments (Undelivered, <1000kg, From Europe):\n",
            "   ShipmentID  Weight(kg) Status OriginPort\n",
            "3        1004         950     No  Rotterdam\n",
            "4        1005         700     No    Hamburg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding new Columns\n",
        "df['Fragile'] = [True, False, True, False, True]\n",
        "# add new Row\n",
        "df.loc[5] = [1006, 1100, 'Delayed', 'Amsterdam', False]\n",
        "# delete\n",
        "df.drop('OriginPort', axis=1, inplace=True)\n",
        "# Update\n",
        "df.loc[df['Status'] == 'No', 'Status'] = 'Pending'\n",
        "\n",
        "# Rename\n",
        "df.rename(columns={'Weight(kg)': 'Weight_kg'}, inplace=True)\n",
        "print(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "2LNYKNXge5pP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ae6082-cf44-4bad-c7c7-b8dbf7bdb115"
      },
      "execution_count": 751,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ShipmentID  Weight_kg      Status  Fragile\n",
            "0        1001        800   Delivered     True\n",
            "1        1002       1200  In Transit    False\n",
            "2        1003        900     Delayed     True\n",
            "3        1004        950     Pending    False\n",
            "4        1005        700     Pending     True\n",
            "5        1006       1100     Delayed    False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting PAndas Dataframe\n",
        "# Sample shipment data from international ports\n",
        "data = {\n",
        "    \"ShipmentID\": [103, 101, 105, 102, 104],\n",
        "    \"OriginPort\": [\"Shanghai\", \"Rotterdam\", \"Singapore\", \"Dubai\", \"Los Angeles\"],\n",
        "    \"DestinationPort\": [\"New York\", \"Hamburg\", \"London\", \"Tokyo\", \"Mumbai\"],\n",
        "    \"Weight_Tons\": [15.4, 25.1, 12.3, 18.7, 20.5],\n",
        "    \"DepartureDate\": pd.to_datetime([\n",
        "        \"2024-09-01\", \"2024-08-25\", \"2024-09-10\", \"2024-08-28\", \"2024-09-03\"\n",
        "    ])\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "r5M2LAGHBcr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f7de34-8f90-4829-aad7-5b3e65c64bd0"
      },
      "execution_count": 752,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ShipmentID   OriginPort DestinationPort  Weight_Tons DepartureDate\n",
            "0         103     Shanghai        New York         15.4    2024-09-01\n",
            "1         101    Rotterdam         Hamburg         25.1    2024-08-25\n",
            "2         105    Singapore          London         12.3    2024-09-10\n",
            "3         102        Dubai           Tokyo         18.7    2024-08-28\n",
            "4         104  Los Angeles          Mumbai         20.5    2024-09-03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort DataFrame by 'Weight_Tons' column in ascending order\n",
        "sorted_df = df.sort_values(by=\"Weight_Tons\", ascending=True)\n",
        "print(\"\\nSorted by Weight (ascending):\\n\", sorted_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGsTxgeEdlmg",
        "outputId": "71cd81ee-a8b7-415c-a5aa-04b7d59e0153"
      },
      "execution_count": 753,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sorted by Weight (ascending):\n",
            "    ShipmentID   OriginPort DestinationPort  Weight_Tons DepartureDate\n",
            "2         105    Singapore          London         12.3    2024-09-10\n",
            "0         103     Shanghai        New York         15.4    2024-09-01\n",
            "3         102        Dubai           Tokyo         18.7    2024-08-28\n",
            "4         104  Los Angeles          Mumbai         20.5    2024-09-03\n",
            "1         101    Rotterdam         Hamburg         25.1    2024-08-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by 'OriginPort' alphabetically, then by 'Weight_Tons'\n",
        "sorted_df = df.sort_values(by=[\"OriginPort\", \"Weight_Tons\"], ascending=[True, False])\n",
        "print(\"\\nSorted by OriginPort (A-Z) and then Weight (high to low):\\n\", sorted_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgFBQwSueZmW",
        "outputId": "714b0201-956e-4493-ab3a-9eee71039373"
      },
      "execution_count": 754,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sorted by OriginPort (A-Z) and then Weight (high to low):\n",
            "    ShipmentID   OriginPort DestinationPort  Weight_Tons DepartureDate\n",
            "3         102        Dubai           Tokyo         18.7    2024-08-28\n",
            "4         104  Los Angeles          Mumbai         20.5    2024-09-03\n",
            "1         101    Rotterdam         Hamburg         25.1    2024-08-25\n",
            "0         103     Shanghai        New York         15.4    2024-09-01\n",
            "2         105    Singapore          London         12.3    2024-09-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set ShipmentID as index and sort by index\n",
        "df_indexed = df.set_index(\"ShipmentID\")\n",
        "sorted_by_index = df_indexed.sort_index()\n",
        "print(\"\\nSorted by ShipmentID (index):\\n\", sorted_by_index)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85hy1ekie5RS",
        "outputId": "b80606d3-4124-4954-e04a-9441ab1eeb15"
      },
      "execution_count": 755,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sorted by ShipmentID (index):\n",
            "              OriginPort DestinationPort  Weight_Tons DepartureDate\n",
            "ShipmentID                                                        \n",
            "101           Rotterdam         Hamburg         25.1    2024-08-25\n",
            "102               Dubai           Tokyo         18.7    2024-08-28\n",
            "103            Shanghai        New York         15.4    2024-09-01\n",
            "104         Los Angeles          Mumbai         20.5    2024-09-03\n",
            "105           Singapore          London         12.3    2024-09-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the DataFrame by 'Weight_Tons' using quicksort algorithm\n",
        "df_quicksort = df.sort_values(by='Weight_Tons', kind='quicksort')\n",
        "print(\"\\nSort using quick sort algo\\n\", df_quicksort)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIebUIiWe6m7",
        "outputId": "c495da06-a352-4c37-c9a4-84fddda09296"
      },
      "execution_count": 756,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sort using quick sort algo\n",
            "    ShipmentID   OriginPort DestinationPort  Weight_Tons DepartureDate\n",
            "2         105    Singapore          London         12.3    2024-09-10\n",
            "0         103     Shanghai        New York         15.4    2024-09-01\n",
            "3         102        Dubai           Tokyo         18.7    2024-08-28\n",
            "4         104  Los Angeles          Mumbai         20.5    2024-09-03\n",
            "1         101    Rotterdam         Hamburg         25.1    2024-08-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reindexing\n",
        "# Dataset: World Vegetation Zones\n",
        "# Original DataFrame with vegetation zones\n",
        "veg_df = pd.DataFrame({\n",
        "    'Zone': ['Tundra', 'Taiga', 'Desert', 'Savanna', 'Rainforest'],\n",
        "    'Continent': ['Arctic', 'Asia', 'Africa', 'Africa', 'South America'],\n",
        "    'Avg_Temp_C': [-10, -5, 35, 28, 26]\n",
        "})\n",
        "print(\"Original Dataframe:\\n\",veg_df)\n",
        "\n",
        "\n",
        "# Set the zone as the index for clarity\n",
        "veg_df = veg_df.set_index('Zone')\n",
        "\n",
        "# Display the original DataFrame\n",
        "print(\"Original World Vegetation Dataset:\\n\", veg_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvlCvBOee7N0",
        "outputId": "d3eeaa7d-051c-4757-c76b-2ee8fa70fd43"
      },
      "execution_count": 757,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataframe:\n",
            "          Zone      Continent  Avg_Temp_C\n",
            "0      Tundra         Arctic         -10\n",
            "1       Taiga           Asia          -5\n",
            "2      Desert         Africa          35\n",
            "3     Savanna         Africa          28\n",
            "4  Rainforest  South America          26\n",
            "Original World Vegetation Dataset:\n",
            "                 Continent  Avg_Temp_C\n",
            "Zone                                 \n",
            "Tundra             Arctic         -10\n",
            "Taiga                Asia          -5\n",
            "Desert             Africa          35\n",
            "Savanna            Africa          28\n",
            "Rainforest  South America          26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reindexing Rows (Add & Reorder Zones)\n",
        "\n",
        "# New desired order of vegetation zones (some new, some missing)\n",
        "new_index = ['Rainforest', 'Savanna', 'Steppe', 'Desert', 'Taiga', 'Tundra']\n",
        "\n",
        "# Reindexing the DataFrame\n",
        "reindexed_veg = veg_df.reindex(new_index)\n",
        "\n",
        "# Display the reindexed DataFrame\n",
        "print(\"\\nReindexed Vegetation Dataset:\\n\", reindexed_veg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9-GW2S2iNTF",
        "outputId": "68c8596f-b360-4b7f-f4f5-e476278613a9"
      },
      "execution_count": 758,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reindexed Vegetation Dataset:\n",
            "                 Continent  Avg_Temp_C\n",
            "Zone                                 \n",
            "Rainforest  South America        26.0\n",
            "Savanna            Africa        28.0\n",
            "Steppe                NaN         NaN\n",
            "Desert             Africa        35.0\n",
            "Taiga                Asia        -5.0\n",
            "Tundra             Arctic       -10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reindexing Columns\n",
        "\n",
        "# Reorder the columns\n",
        "reindexed_columns = veg_df.reindex(columns=['Avg_Temp_C', 'Continent'])\n",
        "\n",
        "# Display the result\n",
        "print(\"\\nReindexed Columns:\\n\", reindexed_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJKT3HYTjQ7z",
        "outputId": "fdfb165e-35c0-47e0-b6b4-92bfa3b695c2"
      },
      "execution_count": 759,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reindexed Columns:\n",
            "             Avg_Temp_C      Continent\n",
            "Zone                                 \n",
            "Tundra             -10         Arctic\n",
            "Taiga               -5           Asia\n",
            "Desert              35         Africa\n",
            "Savanna             28         Africa\n",
            "Rainforest          26  South America\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill Missing Values While Reindexing\n",
        "\n",
        "# Reindex and fill missing values with defaults\n",
        "reindexed_filled = veg_df.reindex(new_index, fill_value='Data N/A')\n",
        "\n",
        "# Display the filled DataFrame\n",
        "print(\"\\nReindexed with Fill Value:\\n\", reindexed_filled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-iQRbZPjl_g",
        "outputId": "0321f172-2fe9-4e6d-9d73-baeb131a22ba"
      },
      "execution_count": 760,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reindexed with Fill Value:\n",
            "                 Continent Avg_Temp_C\n",
            "Zone                                \n",
            "Rainforest  South America         26\n",
            "Savanna            Africa         28\n",
            "Steppe           Data N/A   Data N/A\n",
            "Desert             Africa         35\n",
            "Taiga                Asia         -5\n",
            "Tundra             Arctic        -10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iteration\n",
        "# National Geography Zones dataset that captures region name, average elevation, and annual rainfall.\n",
        "# Sample National Geography dataset\n",
        "geo_df = pd.DataFrame({\n",
        "    'Region': ['Amazon Basin', 'Sahara Desert', 'Himalayas', 'Great Plains'],\n",
        "    'Elevation_m': [200, 450, 5200, 600],  # Elevation in meters\n",
        "    'Rainfall_mm': [2200, 50, 1200, 900]  # Rainfall in millimeters\n",
        "})\n",
        "\n",
        "print(geo_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXQAfRyrnMIT",
        "outputId": "fbe5acc9-b689-43d6-9243-dabbe178e655"
      },
      "execution_count": 761,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Region  Elevation_m  Rainfall_mm\n",
            "0   Amazon Basin          200         2200\n",
            "1  Sahara Desert          450           50\n",
            "2      Himalayas         5200         1200\n",
            "3   Great Plains          600          900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating with iterrows()\n",
        "\n",
        "# Using iterrows() to access each row as a Series\n",
        "for index, row in geo_df.iterrows():\n",
        "    print(f\"Region: {row['Region']}, Elevation: {row['Elevation_m']} m\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezRHkrNeoZ_V",
        "outputId": "2a15ed46-c559-4998-aa38-54f04601863b"
      },
      "execution_count": 762,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Region: Amazon Basin, Elevation: 200 m\n",
            "Region: Sahara Desert, Elevation: 450 m\n",
            "Region: Himalayas, Elevation: 5200 m\n",
            "Region: Great Plains, Elevation: 600 m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating with itertuples()\n",
        "\n",
        "# Using itertuples() for faster row-wise iteration\n",
        "for row in geo_df.itertuples(index=False):\n",
        "    print(f\"{row.Region} receives about {row.Rainfall_mm} mm rainfall annual\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4uWr-zHo05n",
        "outputId": "654f1866-c98a-458f-b83e-1aa047cae719"
      },
      "execution_count": 763,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amazon Basin receives about 2200 mm rainfall annual\n",
            "Sahara Desert receives about 50 mm rainfall annual\n",
            "Himalayas receives about 1200 mm rainfall annual\n",
            "Great Plains receives about 900 mm rainfall annual\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Column-wise Iteration with items()\n",
        "# Iterating through columns using items()\n",
        "for column_name, column_data in geo_df.items():\n",
        "    print(f\"\\nColumn: {column_name}\")\n",
        "    print(f\"Values: {column_data.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNqlBfqfqRl6",
        "outputId": "2de3e3d4-fd1a-4ddf-93ec-15818ac18a5b"
      },
      "execution_count": 764,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Column: Region\n",
            "Values: ['Amazon Basin', 'Sahara Desert', 'Himalayas', 'Great Plains']\n",
            "\n",
            "Column: Elevation_m\n",
            "Values: [200, 450, 5200, 600]\n",
            "\n",
            "Column: Rainfall_mm\n",
            "Values: [2200, 50, 1200, 900]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets: Geography Zones\n",
        "# Northern climate data\n",
        "north_df = pd.DataFrame({\n",
        "    'Region': ['Arctic Circle', 'Northern Tundra'],\n",
        "    'Avg_Temp_C': [-15, -10],\n",
        "    'Biome': ['Tundra', 'Taiga']\n",
        "})\n",
        "print(\"\\nNorthern Climate Data\\n\", north_df)\n",
        "\n",
        "# Southern climate data\n",
        "south_df = pd.DataFrame({\n",
        "    'Region': ['Amazon Basin', 'Patagonian Steppe'],\n",
        "    'Avg_Temp_C': [27, 10],\n",
        "    'Biome': ['Rainforest', 'Steppe']\n",
        "})\n",
        "print(\"\\nSouthern Climate Data\\n\", south_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdEQO0kZqz4s",
        "outputId": "76c968cb-d1e3-4542-b409-7175b0f2a31b"
      },
      "execution_count": 765,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Northern Climate Data\n",
            "             Region  Avg_Temp_C   Biome\n",
            "0    Arctic Circle         -15  Tundra\n",
            "1  Northern Tundra         -10   Taiga\n",
            "\n",
            "Southern Climate Data\n",
            "               Region  Avg_Temp_C       Biome\n",
            "0       Amazon Basin          27  Rainforest\n",
            "1  Patagonian Steppe          10      Steppe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Row-wise Concatenation (axis=0) / For Column (axis=1)\n",
        "# Combine northern and southern data into a single DataFrame\n",
        "combined_df = pd.concat([north_df, south_df], axis=0, ignore_index=True)\n",
        "print(combined_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnZrQVxVsVHP",
        "outputId": "fffd0d1a-bf6d-4e35-a15b-03979cf76825"
      },
      "execution_count": 766,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Region  Avg_Temp_C       Biome\n",
            "0      Arctic Circle         -15      Tundra\n",
            "1    Northern Tundra         -10       Taiga\n",
            "2       Amazon Basin          27  Rainforest\n",
            "3  Patagonian Steppe          10      Steppe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenation with Hierarchical Keys\n",
        "# Add hierarchical row index to identify origin\n",
        "geo_hierarchy = pd.concat([north_df, south_df], keys=['North', 'South'])\n",
        "print(geo_hierarchy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu4n-cNMs3y1",
        "outputId": "93bd17a4-b010-497e-c38f-66fbeb06a5f8"
      },
      "execution_count": 767,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Region  Avg_Temp_C       Biome\n",
            "North 0      Arctic Circle         -15      Tundra\n",
            "      1    Northern Tundra         -10       Taiga\n",
            "South 0       Amazon Basin          27  Rainforest\n",
            "      1  Patagonian Steppe          10      Steppe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passenger reviews and sentiments collected from major international flights.\n",
        "\n",
        "# Sample airline review dataset\n",
        "data = {\n",
        "    'Passenger': ['Alice', 'Bob', 'Carlos', 'Diana', 'Eva'],\n",
        "    'Review': [\n",
        "        'The flight was excellent and on time',\n",
        "        'terrible service and rude crew',\n",
        "        'food was okay but legroom was cramped',\n",
        "        'loved the inflight entertainment options!',\n",
        "        'flight delayed by 3 hours, very annoying'\n",
        "    ],\n",
        "    'Airline': ['Delta', 'United', 'Lufthansa', 'Emirates', 'Qantas']\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpHMV_0TuDaN",
        "outputId": "bf8b3988-1911-4bf6-dc33-41909c0816da"
      },
      "execution_count": 768,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Passenger                                     Review    Airline\n",
            "0     Alice       The flight was excellent and on time      Delta\n",
            "1       Bob             terrible service and rude crew     United\n",
            "2    Carlos      food was okay but legroom was cramped  Lufthansa\n",
            "3     Diana  loved the inflight entertainment options!   Emirates\n",
            "4       Eva   flight delayed by 3 hours, very annoying     Qantas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Cleaning & Filtering\n",
        "\n",
        "# Convert all reviews to lowercase for normalization\n",
        "df['Review_lower'] = df['Review'].str.lower()\n",
        "\n",
        "# Check if the word \"delayed\" is in the review\n",
        "df['Contains_Delayed'] = df['Review_lower'].str.contains('delayed')\n",
        "\n",
        "# Replace the word 'terrible' with 'poor'\n",
        "df['Cleaned_Review'] = df['Review_lower'].str.replace('terrible', 'poor', regex=False)\n",
        "\n",
        "# Count number of characters in the review\n",
        "df['Review_Length'] = df['Review'].str.len()\n",
        "\n",
        "# Extract the first word using regex\n",
        "df['First_Word'] = df['Review'].str.extract(r'(\\w+)')\n",
        "\n",
        "# Display updated DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1nEjbQ1usp9",
        "outputId": "8dfc45bc-7351-4033-e7d1-82472a3e96b6"
      },
      "execution_count": 769,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Passenger                                     Review    Airline  \\\n",
            "0     Alice       The flight was excellent and on time      Delta   \n",
            "1       Bob             terrible service and rude crew     United   \n",
            "2    Carlos      food was okay but legroom was cramped  Lufthansa   \n",
            "3     Diana  loved the inflight entertainment options!   Emirates   \n",
            "4       Eva   flight delayed by 3 hours, very annoying     Qantas   \n",
            "\n",
            "                                Review_lower  Contains_Delayed  \\\n",
            "0       the flight was excellent and on time             False   \n",
            "1             terrible service and rude crew             False   \n",
            "2      food was okay but legroom was cramped             False   \n",
            "3  loved the inflight entertainment options!             False   \n",
            "4   flight delayed by 3 hours, very annoying              True   \n",
            "\n",
            "                              Cleaned_Review  Review_Length First_Word  \n",
            "0       the flight was excellent and on time             36        The  \n",
            "1                 poor service and rude crew             30   terrible  \n",
            "2      food was okay but legroom was cramped             37       food  \n",
            "3  loved the inflight entertainment options!             41      loved  \n",
            "4   flight delayed by 3 hours, very annoying             40     flight  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating categorical Types\n",
        "# Sample shipment data\n",
        "data = {\n",
        "    'ShipmentID': ['S001', 'S002', 'S003', 'S004', 'S005'],\n",
        "    'PortofOrigin': ['Shanghai', 'Mumbai', 'Singapore', 'Rotterdam', 'Mumbai'],\n",
        "    'ShipmentStatus': ['In Transit', 'Delivered', 'Delayed', 'In Transit', 'Delivered']\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Before:\",df)\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "# Convert ShipmentStatus to categorical type\n",
        "df['ShipmentStatus'] = pd.Categorical(df['ShipmentStatus'])\n",
        "\n",
        "# Display DataFrame and type info\n",
        "print(df)\n",
        "print(\"\\nData types:\\n\", df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVn9s0VZv21d",
        "outputId": "f0fdbb28-1d2d-491d-fde4-784ab015c608"
      },
      "execution_count": 770,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:   ShipmentID PortofOrigin ShipmentStatus\n",
            "0       S001     Shanghai     In Transit\n",
            "1       S002       Mumbai      Delivered\n",
            "2       S003    Singapore        Delayed\n",
            "3       S004    Rotterdam     In Transit\n",
            "4       S005       Mumbai      Delivered\n",
            "\n",
            "Data types:\n",
            " ShipmentID        object\n",
            "PortofOrigin      object\n",
            "ShipmentStatus    object\n",
            "dtype: object\n",
            "  ShipmentID PortofOrigin ShipmentStatus\n",
            "0       S001     Shanghai     In Transit\n",
            "1       S002       Mumbai      Delivered\n",
            "2       S003    Singapore        Delayed\n",
            "3       S004    Rotterdam     In Transit\n",
            "4       S005       Mumbai      Delivered\n",
            "\n",
            "Data types:\n",
            " ShipmentID          object\n",
            "PortofOrigin        object\n",
            "ShipmentStatus    category\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting, Ordering, and Comparison\n",
        "\n",
        "# Define a specific order to categorical values, enabling logical sorting and comparisons.\n",
        "\n",
        "# Define custom order for status\n",
        "status_order = ['Delayed', 'In Transit', 'Delivered']\n",
        "\n",
        "# Convert to ordered categorical\n",
        "df['ShipmentStatus'] = pd.Categorical(df['ShipmentStatus'], categories=status_order, ordered=True)\n",
        "\n",
        "# Sort DataFrame based on ordered status\n",
        "sorted_df = df.sort_values('ShipmentStatus')\n",
        "\n",
        "print(sorted_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpYFrlZDyxz1",
        "outputId": "f705456d-04ea-4832-eb53-f1b7bca45657"
      },
      "execution_count": 771,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ShipmentID PortofOrigin ShipmentStatus\n",
            "2       S003    Singapore        Delayed\n",
            "0       S001     Shanghai     In Transit\n",
            "3       S004    Rotterdam     In Transit\n",
            "1       S002       Mumbai      Delivered\n",
            "4       S005       Mumbai      Delivered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Patient Vitals Monitoring (5 patients x 4 vitals)\n",
        "# Create a simulated hospital vitals dataset\n",
        "data = {\n",
        "    'PatientID': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
        "    'Temperature_C': [36.6, np.nan, 38.1, 37.5, np.nan],\n",
        "    'Blood_Pressure': ['120/80', '130/85', np.nan, '110/70', '125/82'],\n",
        "    'Heart_Rate': [72, 85, 80, np.nan, np.nan],\n",
        "    'Respiratory_Rate': [18, np.nan, 20, 19, 21]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO_qQkgi05T1",
        "outputId": "108b76b1-b2fc-42e8-feb2-91220197932d"
      },
      "execution_count": 772,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PatientID  Temperature_C Blood_Pressure  Heart_Rate  Respiratory_Rate\n",
            "0      P001           36.6         120/80        72.0              18.0\n",
            "1      P002            NaN         130/85        85.0               NaN\n",
            "2      P003           38.1            NaN        80.0              20.0\n",
            "3      P004           37.5         110/70         NaN              19.0\n",
            "4      P005            NaN         125/82         NaN              21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting Missing Values\n",
        "\n",
        "# Detecting missing values in each column\n",
        "missing_values = df.isna()\n",
        "\n",
        "# Count of missing values per column\n",
        "missing_counts = df.isna().sum()\n",
        "\n",
        "print(\"Missing matrix:\\n\", missing_values)\n",
        "print(\"\\nMissing counts:\\n\", missing_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_sVjDkv2dGD",
        "outputId": "2d77117a-44e3-49c6-c84c-e2c310b60be1"
      },
      "execution_count": 773,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing matrix:\n",
            "    PatientID  Temperature_C  Blood_Pressure  Heart_Rate  Respiratory_Rate\n",
            "0      False          False           False       False             False\n",
            "1      False           True           False       False              True\n",
            "2      False          False            True       False             False\n",
            "3      False          False           False        True             False\n",
            "4      False           True           False        True             False\n",
            "\n",
            "Missing counts:\n",
            " PatientID           0\n",
            "Temperature_C       2\n",
            "Blood_Pressure      1\n",
            "Heart_Rate          2\n",
            "Respiratory_Rate    1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling Missing Values (fillna)\n",
        "\n",
        "# Fill missing temperature with mean of existing temperatures\n",
        "df['Temperature_C'] = df['Temperature_C'].fillna(df['Temperature_C'].mean())\n",
        "\n",
        "# Fill missing heart rate with a constant value (e.g., 75)\n",
        "df['Heart_Rate'] = df['Heart_Rate'].fillna(75)\n",
        "\n",
        "print(\"\\nAfter filling missing values:\\n\", df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc-zFGKP4GW9",
        "outputId": "be97dd08-806d-4291-8bd9-4152057940c8"
      },
      "execution_count": 774,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After filling missing values:\n",
            "   PatientID  Temperature_C Blood_Pressure  Heart_Rate  Respiratory_Rate\n",
            "0      P001           36.6         120/80        72.0              18.0\n",
            "1      P002           37.4         130/85        85.0               NaN\n",
            "2      P003           38.1            NaN        80.0              20.0\n",
            "3      P004           37.5         110/70        75.0              19.0\n",
            "4      P005           37.4         125/82        75.0              21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Rows/Columns with Missing Data (dropna)\n",
        "# Drop rows where all vitals are missing\n",
        "df_dropped = df.dropna(how='all', subset=['Temperature_C', 'Blood_Pressure', 'Heart_Rate', 'Respiratory_Rate'])\n",
        "print(\"After Dropping Rows with All Vitals missing:\\n\",df_dropped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqub3iZZ4Hxy",
        "outputId": "c59cbfdf-101d-4eee-841d-a9764a588cc6"
      },
      "execution_count": 775,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Dropping Rows with All Vitals missing:\n",
            "   PatientID  Temperature_C Blood_Pressure  Heart_Rate  Respiratory_Rate\n",
            "0      P001           36.6         120/80        72.0              18.0\n",
            "1      P002           37.4         130/85        85.0               NaN\n",
            "2      P003           38.1            NaN        80.0              20.0\n",
            "3      P004           37.5         110/70        75.0              19.0\n",
            "4      P005           37.4         125/82        75.0              21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling duplicates\n",
        "\n",
        "# Create logistics dataset\n",
        "# Create sample dataset representing cargo shipments\n",
        "data = {\n",
        "    'Container ID': ['C001', 'C002', 'C003', 'C001', 'C004', 'C002'],\n",
        "    'Origin_Port': ['Shanghai', 'Rotterdam', 'Dubai', 'Shanghai', 'Singapore', 'Rotterdam'],\n",
        "    'Destination_Port': ['Los Angeles', 'New York', 'Hamburg', 'Los Angeles', 'Tokyo', 'New York'],\n",
        "    'Weight_Tons': [20, 25, 18, 20, 30, 25]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNVCBNTD5Ktv",
        "outputId": "b00d8aa1-2113-4590-c9be-db70bb8f4b75"
      },
      "execution_count": 776,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "  Container ID Origin_Port Destination_Port  Weight_Tons\n",
            "0         C001    Shanghai      Los Angeles           20\n",
            "1         C002   Rotterdam         New York           25\n",
            "2         C003       Dubai          Hamburg           18\n",
            "3         C001    Shanghai      Los Angeles           20\n",
            "4         C004   Singapore            Tokyo           30\n",
            "5         C002   Rotterdam         New York           25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Detect duplicated rows (entire row)\n",
        "print(\"\\nDuplicated Rows (Boolean Mask):\")\n",
        "print(df.duplicated())\n",
        "\n",
        "# Drop duplicate rows (entirely duplicated rows)\n",
        "df_dedup = df.drop_duplicates()\n",
        "print(\"\\nDataFrame after removing completely duplicated rows:\")\n",
        "print(df_dedup)\n",
        "\n",
        "# Drop duplicates based on 'Container ID' column\n",
        "df_unique_containers = df.drop_duplicates(subset=['Container ID'])\n",
        "print(\"\\nDataFrame after keeping unique 'Container ID's only:\")\n",
        "print(df_unique_containers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ5-crI-7XZk",
        "outputId": "84dab736-644d-4f7b-e423-9a3f1296acbf"
      },
      "execution_count": 777,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Duplicated Rows (Boolean Mask):\n",
            "0    False\n",
            "1    False\n",
            "2    False\n",
            "3     True\n",
            "4    False\n",
            "5     True\n",
            "dtype: bool\n",
            "\n",
            "DataFrame after removing completely duplicated rows:\n",
            "  Container ID Origin_Port Destination_Port  Weight_Tons\n",
            "0         C001    Shanghai      Los Angeles           20\n",
            "1         C002   Rotterdam         New York           25\n",
            "2         C003       Dubai          Hamburg           18\n",
            "4         C004   Singapore            Tokyo           30\n",
            "\n",
            "DataFrame after keeping unique 'Container ID's only:\n",
            "  Container ID Origin_Port Destination_Port  Weight_Tons\n",
            "0         C001    Shanghai      Los Angeles           20\n",
            "1         C002   Rotterdam         New York           25\n",
            "2         C003       Dubai          Hamburg           18\n",
            "4         C004   Singapore            Tokyo           30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Handling duplicates\n",
        "\n",
        "# Create logistics dataset\n",
        "data = {\n",
        "    'Container ID': ['C001', 'C002', 'C003', 'C001', 'C004', 'C002'],\n",
        "    'Origin_Port': ['Shanghai', 'Rotterdam', 'Dubai', 'Shanghai', 'Singapore', 'Rotterdam'],\n",
        "    'Destination_Port': ['Los Angeles', 'New York', 'Hamburg', 'Los Angeles', 'Tokyo', 'New York'],\n",
        "    'Weight_Tons': [20, 25, 18, 20, 30, 25]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Retrieve and Count Unique Elements\n",
        "\n",
        "# Count of unique destination ports\n",
        "unique_dest_ports = df['Destination_Port'].nunique()\n",
        "print(\"Unique Destination Ports:\", unique_dest_ports)\n",
        "\n",
        "# Unique container IDs\n",
        "print(\"Unique Container IDs:\", df['Container ID'].unique())\n",
        "\n",
        "# Frequency of each origin port\n",
        "print(\"Origin Port Frequency:\\n\", df['Origin_Port'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPMguMht8AgT",
        "outputId": "4db68c32-2cff-48ef-bdf5-6eb8c86a534c"
      },
      "execution_count": 778,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame:\n",
            "  Container ID Origin_Port Destination_Port  Weight_Tons\n",
            "0         C001    Shanghai      Los Angeles           20\n",
            "1         C002   Rotterdam         New York           25\n",
            "2         C003       Dubai          Hamburg           18\n",
            "3         C001    Shanghai      Los Angeles           20\n",
            "4         C004   Singapore            Tokyo           30\n",
            "5         C002   Rotterdam         New York           25\n",
            "Unique Destination Ports: 4\n",
            "Unique Container IDs: ['C001' 'C002' 'C003' 'C004']\n",
            "Origin Port Frequency:\n",
            " Origin_Port\n",
            "Shanghai     2\n",
            "Rotterdam    2\n",
            "Dubai        1\n",
            "Singapore    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Duplicated Labels (Row/Column Indexes)\n",
        "# Create sample dataframe with duplicate column labels\n",
        "df_dup_cols = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'A'])\n",
        "\n",
        "print(df_dup_cols)\n",
        "\n",
        "print(\"Duplicate Columns:\\n\", df_dup_cols.columns.duplicated()) # Detect duplicate columns\n",
        "\n",
        "# Create sample dataframe with duplicate row indices\n",
        "df_dup_index = pd.DataFrame({\n",
        "    'Shipment': ['Box1', 'Box2', 'Box3'],\n",
        "    'Weight': [10, 15, 12]\n",
        "}, index=[0, 1, 1]) # duplicate index 1\n",
        "\n",
        "print(df_dup_index)\n",
        "\n",
        "print(\"Duplicate Index:\\n\", df_dup_index.index.duplicated()) # Detect duplicate indices"
      ],
      "metadata": {
        "id": "M0W7qLEn9ZZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251f6b77-5625-4dc0-dcb8-e7c9e4483da5"
      },
      "execution_count": 779,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   A  B  A\n",
            "0  1  2  3\n",
            "1  4  5  6\n",
            "Duplicate Columns:\n",
            " [False False  True]\n",
            "  Shipment  Weight\n",
            "0     Box1      10\n",
            "1     Box2      15\n",
            "1     Box3      12\n",
            "Duplicate Index:\n",
            " [False False  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining and reshaping\n",
        "# concat() – Combine OTA and Airline Bookings\n",
        "# Create OTA bookings DataFrame\n",
        "ota_data = pd.DataFrame({\n",
        "    'PassengerID': [101, 102, 103],\n",
        "    'Origin': ['JFK', 'LHR', 'DXB'],\n",
        "    'Destination': ['CDG', 'DEL', 'HND'],\n",
        "    'FareUSD': [520, 690, 830]\n",
        "})\n",
        "\n",
        "# Create Airline website bookings DataFrame\n",
        "airline_data = pd.DataFrame({\n",
        "    'PassengerID': [104, 105],\n",
        "    'Origin': ['SIN', 'SFO'],\n",
        "    'Destination': ['SYD', 'ICN'],\n",
        "    'FareUSD': [720, 640]\n",
        "})\n",
        "\n",
        "# Combine both datasets vertically (row-wise)\n",
        "combined_data = pd.concat([ota_data, airline_data], ignore_index=True)\n",
        "\n",
        "print(combined_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLGzS9h3_xzg",
        "outputId": "6d434a0d-c271-4654-d7f0-3dd0ace73799"
      },
      "execution_count": 780,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerID Origin Destination  FareUSD\n",
            "0          101    JFK         CDG      520\n",
            "1          102    LHR         DEL      690\n",
            "2          103    DXB         HND      830\n",
            "3          104    SIN         SYD      720\n",
            "4          105    SFO         ICN      640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge() - Add Airport Metadata\n",
        "# Main ticket data\n",
        "tickets = pd.DataFrame({\n",
        "    'PassengerID': [101, 102, 103],\n",
        "    'Origin': ['JFK', 'LHR', 'DXB'],\n",
        "    'Destination': ['CDG', 'DEL', 'HND']\n",
        "})\n",
        "\n",
        "# Airport metadata\n",
        "airports = pd.DataFrame({\n",
        "    'AirportCode': ['JFK', 'LHR', 'DXB', 'CDG', 'DEL', 'HND'],\n",
        "    'Country': ['USA', 'UK', 'UAE', 'France', 'India', 'Japan']\n",
        "})\n",
        "\n",
        "# Merge ticket data with airport info on Origin code\n",
        "merged = tickets.merge(airports, how='left', left_on='Origin', right_on='AirportCode')\n",
        "\n",
        "print(merged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0_mSDvbCUoa",
        "outputId": "4e0f72a2-32a7-40a8-e51d-9b953033158f"
      },
      "execution_count": 781,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerID Origin Destination AirportCode Country\n",
            "0          101    JFK         CDG         JFK     USA\n",
            "1          102    LHR         DEL         LHR      UK\n",
            "2          103    DXB         HND         DXB     UAE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Schedule DataFrame: flight details\n",
        "schedule_df = pd.DataFrame({\n",
        "    'FlightNo': ['AI101', 'BA204', 'LH709', 'EK501'],\n",
        "    'Origin': ['Delhi', 'London', 'Frankfurt', 'Dubai'],\n",
        "    'Destination': ['New York', 'Mumbai', 'Tokyo', 'Singapore']\n",
        "}).set_index('FlightNo')\n",
        "\n",
        "# Prices DataFrame: ticket prices\n",
        "prices_df = pd.DataFrame({\n",
        "    'FlightNo': ['AI101', 'BA204', 'SQ002', 'EK501'],\n",
        "    'FareUSD': [850, 920, 780, 730]\n",
        "}).set_index('FlightNo')\n",
        "\n",
        "# Different join types\n",
        "\n",
        "# LEFT JOIN: keeps all rows from the schedule_df, missing prices = NaN\n",
        "left_join = schedule_df.join(prices_df, how='left')\n",
        "print(\"Left Join (All Schedule Flights):\")\n",
        "print(left_join)\n",
        "print(\"\\n\")\n",
        "\n",
        "# RIGHT JOIN: keeps all rows from prices_df, missing schedule = NaN\n",
        "right_join = schedule_df.join(prices_df, how='right')\n",
        "print(\"Right Join (All Priced Flights):\")\n",
        "print(right_join)\n",
        "print(\"\\n\")\n",
        "\n",
        "# INNER JOIN: keeps only matching FlightNo in both\n",
        "inner_join = schedule_df.join(prices_df, how='inner')\n",
        "print(\"Inner Join (Matching Flights Only):\")\n",
        "print(inner_join)\n",
        "print(\"\\n\")\n",
        "\n",
        "# OUTER JOIN: keeps all flights from both DataFrames\n",
        "outer_join = schedule_df.join(prices_df, how='outer')\n",
        "print(\"Outer Join (All Flights from Both Tables):\")\n",
        "print(outer_join)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztTxejRuCpDc",
        "outputId": "a9918432-8804-4418-d08d-84dc794c0b73"
      },
      "execution_count": 782,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left Join (All Schedule Flights):\n",
            "             Origin Destination  FareUSD\n",
            "FlightNo                                \n",
            "AI101         Delhi    New York    850.0\n",
            "BA204        London      Mumbai    920.0\n",
            "LH709     Frankfurt       Tokyo      NaN\n",
            "EK501         Dubai   Singapore    730.0\n",
            "\n",
            "\n",
            "Right Join (All Priced Flights):\n",
            "          Origin Destination  FareUSD\n",
            "FlightNo                             \n",
            "AI101      Delhi    New York      850\n",
            "BA204     London      Mumbai      920\n",
            "SQ002        NaN         NaN      780\n",
            "EK501      Dubai   Singapore      730\n",
            "\n",
            "\n",
            "Inner Join (Matching Flights Only):\n",
            "          Origin Destination  FareUSD\n",
            "FlightNo                             \n",
            "AI101      Delhi    New York      850\n",
            "BA204     London      Mumbai      920\n",
            "EK501      Dubai   Singapore      730\n",
            "\n",
            "\n",
            "Outer Join (All Flights from Both Tables):\n",
            "             Origin Destination  FareUSD\n",
            "FlightNo                                \n",
            "AI101         Delhi    New York    850.0\n",
            "BA204        London      Mumbai    920.0\n",
            "EK501         Dubai   Singapore    730.0\n",
            "LH709     Frankfurt       Tokyo      NaN\n",
            "SQ002           NaN         NaN    780.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pivot() - Reshape flight fare data from long to wide format\n",
        "# Long-form fare data\n",
        "fare_data = pd.DataFrame({\n",
        "    'Route': ['JFK-CDG', 'NYC-LON', 'NYC-LON', 'DEL-TYO', 'DEL-TYO', 'DEL-TYO'],\n",
        "    'Class': ['Economy', 'Business', 'First', 'Economy', 'Business', 'First'],\n",
        "    'FareUSD': [500, 1200, 2200, 450, 1100, 2100]\n",
        "})\n",
        "print(\"All data\\n\", fare_data)\n",
        "\n",
        "# Pivot the data: one row per route, one column per class\n",
        "pivoted_fares = fare_data.pivot(index='Route', columns='Class', values='FareUSD')\n",
        "print(\"\\nPivot Data\\n\",pivoted_fares)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJXzfFxiEXlI",
        "outputId": "08a4b258-1367-4ddd-965f-acf9331d0f3d"
      },
      "execution_count": 783,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data\n",
            "      Route     Class  FareUSD\n",
            "0  JFK-CDG   Economy      500\n",
            "1  NYC-LON  Business     1200\n",
            "2  NYC-LON     First     2200\n",
            "3  DEL-TYO   Economy      450\n",
            "4  DEL-TYO  Business     1100\n",
            "5  DEL-TYO     First     2100\n",
            "\n",
            "Pivot Data\n",
            " Class    Business  Economy   First\n",
            "Route                             \n",
            "DEL-TYO    1100.0    450.0  2100.0\n",
            "JFK-CDG       NaN    500.0     NaN\n",
            "NYC-LON    1200.0      NaN  2200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pivot_table() - Average Fare by Origin and Class\n",
        "\n",
        "# Flight ticket records\n",
        "tickets = pd.DataFrame({\n",
        "    'Origin': ['JFK', 'JFK', 'LHR', 'LHR', 'DXB', 'DXB'],\n",
        "    'Class': ['Economy', 'Business', 'Economy', 'Business', 'Economy', 'Business'],\n",
        "    'FareUSD': [520, 1120, 480, 980, 430, 900]\n",
        "})\n",
        "\n",
        "# Create a pivot table showing average fare by origin and class\n",
        "fare_pivot = tickets.pivot_table(values='FareUSD',\n",
        "                                 index='Origin',\n",
        "                                 columns='Class',\n",
        "                                 aggfunc='mean')\n",
        "\n",
        "print(fare_pivot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz-ry4grGkmO",
        "outputId": "cf83545b-88b5-40c7-9cdd-f74c649717de"
      },
      "execution_count": 785,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class   Business  Economy\n",
            "Origin                   \n",
            "DXB        900.0    430.0\n",
            "JFK       1120.0    520.0\n",
            "LHR        980.0    480.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMBKTDVgHyXK"
      },
      "execution_count": 784,
      "outputs": []
    }
  ]
}